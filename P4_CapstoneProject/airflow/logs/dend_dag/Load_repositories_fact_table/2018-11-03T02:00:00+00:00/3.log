[2019-11-17 15:20:42,036] {taskinstance.py:620} INFO - Dependencies all met for <TaskInstance: dend_dag.Load_repositories_fact_table 2018-11-03T02:00:00+00:00 [queued]>
[2019-11-17 15:20:42,041] {taskinstance.py:620} INFO - Dependencies all met for <TaskInstance: dend_dag.Load_repositories_fact_table 2018-11-03T02:00:00+00:00 [queued]>
[2019-11-17 15:20:42,041] {taskinstance.py:838} INFO - 
--------------------------------------------------------------------------------
[2019-11-17 15:20:42,041] {taskinstance.py:839} INFO - Starting attempt 3 of 4
[2019-11-17 15:20:42,041] {taskinstance.py:840} INFO - 
--------------------------------------------------------------------------------
[2019-11-17 15:20:42,045] {taskinstance.py:859} INFO - Executing <Task(LoadFactOperator): Load_repositories_fact_table> on 2018-11-03T02:00:00+00:00
[2019-11-17 15:20:42,045] {base_task_runner.py:133} INFO - Running: ['airflow', 'run', 'dend_dag', 'Load_repositories_fact_table', '2018-11-03T02:00:00+00:00', '--job_id', '250', '--pool', 'default_pool', '--raw', '-sd', 'DAGS_FOLDER/dend_dag.py', '--cfg_path', '/var/folders/8q/nyxhvd6d55nfqjdbrybk6jpw0000gn/T/tmp_9p_y01z']
[2019-11-17 15:20:42,702] {base_task_runner.py:115} INFO - Job 250: Subtask Load_repositories_fact_table /Users/likejun/anaconda3/lib/python3.7/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
[2019-11-17 15:20:42,702] {base_task_runner.py:115} INFO - Job 250: Subtask Load_repositories_fact_table   """)
[2019-11-17 15:20:42,775] {base_task_runner.py:115} INFO - Job 250: Subtask Load_repositories_fact_table [2019-11-17 15:20:42,774] {__init__.py:51} INFO - Using executor SequentialExecutor
[2019-11-17 15:20:43,063] {base_task_runner.py:115} INFO - Job 250: Subtask Load_repositories_fact_table [2019-11-17 15:20:43,063] {dagbag.py:90} INFO - Filling up the DagBag from /Users/likejun/airflow/dags/dend_dag.py
[2019-11-17 15:20:43,077] {base_task_runner.py:115} INFO - Job 250: Subtask Load_repositories_fact_table [2019-11-17 15:20:43,076] {cli.py:516} INFO - Running <TaskInstance: dend_dag.Load_repositories_fact_table 2018-11-03T02:00:00+00:00 [running]> on host likejundeMacBook-Pro.local
[2019-11-17 15:20:43,083] {load_facts.py:21} INFO - LoadFactOperator for repository_fact
[2019-11-17 15:20:43,089] {logging_mixin.py:95} INFO - [[34m2019-11-17 15:20:43,088[0m] {[34mbase_hook.py:[0m84} INFO[0m - Using connection to: [1mid: redshift. Host: redshift-cluster.chjcdyihped1.us-west-2.redshift.amazonaws.com, Port: 5439, Schema: dev, Login: awsuser, Password: XXXXXXXX, extra: {}[0m[0m
[2019-11-17 15:20:45,644] {logging_mixin.py:95} INFO - [[34m2019-11-17 15:20:45,644[0m] {[34mdbapi_hook.py:[0m171} INFO[0m - 
    INSERT INTO repository_fact
        (SELECT
            sp."repository id" AS repository_id,
            sp."repository stars count" AS stars,
            sp."repository forks count" AS forks,
            sp."repository watchers count" AS watchers,
            sp."repository contributors count" AS contributors,
            sp."repository size" AS size,
            sp."repository name with owner" AS repo,
            sv.id AS version_id,
            sv.project_id,
            sp."repository created timestamp" AS create_time,
            sd.id AS dependency_id
            FROM staging_projects sp
            JOIN staging_versions sv
            ON sp.id = sv.project_id
            JOIN staging_dependencies sd
            ON sp.id = sd."project id"
            WHERE sp."repository id" IS NOT NULL)
    [0m
[2019-11-17 15:20:54,736] {taskinstance.py:1051} ERROR - Cannot insert a NULL value into column create_time
DETAIL:  
  -----------------------------------------------
  error:  Cannot insert a NULL value into column create_time
  code:      8007
  context:   query execution
  query:     2575
  location:  column:10
  process:   query2_122_2575 [pid=13973]
  -----------------------------------------------

Traceback (most recent call last):
  File "/Users/likejun/anaconda3/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 926, in _run_raw_task
    result = task_copy.execute(context=context)
  File "/Users/likejun/airflow/plugins/operators/load_facts.py", line 30, in execute
    pg_hook.run(SqlQueries.repository_table_select)
  File "/Users/likejun/anaconda3/lib/python3.7/site-packages/airflow/hooks/dbapi_hook.py", line 172, in run
    cur.execute(s)
psycopg2.InternalError: Cannot insert a NULL value into column create_time
DETAIL:  
  -----------------------------------------------
  error:  Cannot insert a NULL value into column create_time
  code:      8007
  context:   query execution
  query:     2575
  location:  column:10
  process:   query2_122_2575 [pid=13973]
  -----------------------------------------------


[2019-11-17 15:20:54,738] {taskinstance.py:1074} INFO - Marking task as UP_FOR_RETRY
[2019-11-17 15:20:54,749] {base_task_runner.py:115} INFO - Job 250: Subtask Load_repositories_fact_table Traceback (most recent call last):
[2019-11-17 15:20:54,749] {base_task_runner.py:115} INFO - Job 250: Subtask Load_repositories_fact_table   File "/Users/likejun/anaconda3/bin/airflow", line 32, in <module>
[2019-11-17 15:20:54,749] {base_task_runner.py:115} INFO - Job 250: Subtask Load_repositories_fact_table     args.func(args)
[2019-11-17 15:20:54,749] {base_task_runner.py:115} INFO - Job 250: Subtask Load_repositories_fact_table   File "/Users/likejun/anaconda3/lib/python3.7/site-packages/airflow/utils/cli.py", line 74, in wrapper
[2019-11-17 15:20:54,749] {base_task_runner.py:115} INFO - Job 250: Subtask Load_repositories_fact_table     return f(*args, **kwargs)
[2019-11-17 15:20:54,750] {base_task_runner.py:115} INFO - Job 250: Subtask Load_repositories_fact_table   File "/Users/likejun/anaconda3/lib/python3.7/site-packages/airflow/bin/cli.py", line 522, in run
[2019-11-17 15:20:54,750] {base_task_runner.py:115} INFO - Job 250: Subtask Load_repositories_fact_table     _run(args, dag, ti)
[2019-11-17 15:20:54,750] {base_task_runner.py:115} INFO - Job 250: Subtask Load_repositories_fact_table   File "/Users/likejun/anaconda3/lib/python3.7/site-packages/airflow/bin/cli.py", line 440, in _run
[2019-11-17 15:20:54,750] {base_task_runner.py:115} INFO - Job 250: Subtask Load_repositories_fact_table     pool=args.pool,
[2019-11-17 15:20:54,750] {base_task_runner.py:115} INFO - Job 250: Subtask Load_repositories_fact_table   File "/Users/likejun/anaconda3/lib/python3.7/site-packages/airflow/utils/db.py", line 74, in wrapper
[2019-11-17 15:20:54,750] {base_task_runner.py:115} INFO - Job 250: Subtask Load_repositories_fact_table     return func(*args, **kwargs)
[2019-11-17 15:20:54,750] {base_task_runner.py:115} INFO - Job 250: Subtask Load_repositories_fact_table   File "/Users/likejun/anaconda3/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 926, in _run_raw_task
[2019-11-17 15:20:54,750] {base_task_runner.py:115} INFO - Job 250: Subtask Load_repositories_fact_table     result = task_copy.execute(context=context)
[2019-11-17 15:20:54,750] {base_task_runner.py:115} INFO - Job 250: Subtask Load_repositories_fact_table   File "/Users/likejun/airflow/plugins/operators/load_facts.py", line 30, in execute
[2019-11-17 15:20:54,750] {base_task_runner.py:115} INFO - Job 250: Subtask Load_repositories_fact_table     pg_hook.run(SqlQueries.repository_table_select)
[2019-11-17 15:20:54,750] {base_task_runner.py:115} INFO - Job 250: Subtask Load_repositories_fact_table   File "/Users/likejun/anaconda3/lib/python3.7/site-packages/airflow/hooks/dbapi_hook.py", line 172, in run
[2019-11-17 15:20:54,750] {base_task_runner.py:115} INFO - Job 250: Subtask Load_repositories_fact_table     cur.execute(s)
[2019-11-17 15:20:54,750] {base_task_runner.py:115} INFO - Job 250: Subtask Load_repositories_fact_table psycopg2.InternalError: Cannot insert a NULL value into column create_time
[2019-11-17 15:20:54,750] {base_task_runner.py:115} INFO - Job 250: Subtask Load_repositories_fact_table DETAIL:  
[2019-11-17 15:20:54,750] {base_task_runner.py:115} INFO - Job 250: Subtask Load_repositories_fact_table   -----------------------------------------------
[2019-11-17 15:20:54,750] {base_task_runner.py:115} INFO - Job 250: Subtask Load_repositories_fact_table   error:  Cannot insert a NULL value into column create_time
[2019-11-17 15:20:54,750] {base_task_runner.py:115} INFO - Job 250: Subtask Load_repositories_fact_table   code:      8007
[2019-11-17 15:20:54,750] {base_task_runner.py:115} INFO - Job 250: Subtask Load_repositories_fact_table   context:   query execution
[2019-11-17 15:20:54,750] {base_task_runner.py:115} INFO - Job 250: Subtask Load_repositories_fact_table   query:     2575
[2019-11-17 15:20:54,750] {base_task_runner.py:115} INFO - Job 250: Subtask Load_repositories_fact_table   location:  column:10
[2019-11-17 15:20:54,750] {base_task_runner.py:115} INFO - Job 250: Subtask Load_repositories_fact_table   process:   query2_122_2575 [pid=13973]
[2019-11-17 15:20:54,750] {base_task_runner.py:115} INFO - Job 250: Subtask Load_repositories_fact_table   -----------------------------------------------
[2019-11-17 15:20:54,750] {base_task_runner.py:115} INFO - Job 250: Subtask Load_repositories_fact_table 
[2019-11-17 15:20:54,751] {base_task_runner.py:115} INFO - Job 250: Subtask Load_repositories_fact_table 
[2019-11-17 15:20:57,048] {logging_mixin.py:95} INFO - [[34m2019-11-17 15:20:57,047[0m] {[34mlocal_task_job.py:[0m105} INFO[0m - Task exited with return code 1[0m

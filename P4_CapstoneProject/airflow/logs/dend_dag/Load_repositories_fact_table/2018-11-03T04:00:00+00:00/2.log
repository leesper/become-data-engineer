[2019-11-17 17:58:49,500] {taskinstance.py:620} INFO - Dependencies all met for <TaskInstance: dend_dag.Load_repositories_fact_table 2018-11-03T04:00:00+00:00 [queued]>
[2019-11-17 17:58:49,504] {taskinstance.py:620} INFO - Dependencies all met for <TaskInstance: dend_dag.Load_repositories_fact_table 2018-11-03T04:00:00+00:00 [queued]>
[2019-11-17 17:58:49,504] {taskinstance.py:838} INFO - 
--------------------------------------------------------------------------------
[2019-11-17 17:58:49,504] {taskinstance.py:839} INFO - Starting attempt 2 of 4
[2019-11-17 17:58:49,504] {taskinstance.py:840} INFO - 
--------------------------------------------------------------------------------
[2019-11-17 17:58:49,509] {taskinstance.py:859} INFO - Executing <Task(LoadFactOperator): Load_repositories_fact_table> on 2018-11-03T04:00:00+00:00
[2019-11-17 17:58:49,509] {base_task_runner.py:133} INFO - Running: ['airflow', 'run', 'dend_dag', 'Load_repositories_fact_table', '2018-11-03T04:00:00+00:00', '--job_id', '269', '--pool', 'default_pool', '--raw', '-sd', 'DAGS_FOLDER/dend_dag.py', '--cfg_path', '/var/folders/8q/nyxhvd6d55nfqjdbrybk6jpw0000gn/T/tmpb_som49p']
[2019-11-17 17:58:50,217] {base_task_runner.py:115} INFO - Job 269: Subtask Load_repositories_fact_table /Users/likejun/anaconda3/lib/python3.7/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
[2019-11-17 17:58:50,218] {base_task_runner.py:115} INFO - Job 269: Subtask Load_repositories_fact_table   """)
[2019-11-17 17:58:50,303] {base_task_runner.py:115} INFO - Job 269: Subtask Load_repositories_fact_table [2019-11-17 17:58:50,303] {__init__.py:51} INFO - Using executor SequentialExecutor
[2019-11-17 17:58:50,593] {base_task_runner.py:115} INFO - Job 269: Subtask Load_repositories_fact_table [2019-11-17 17:58:50,593] {dagbag.py:90} INFO - Filling up the DagBag from /Users/likejun/airflow/dags/dend_dag.py
[2019-11-17 17:58:50,606] {base_task_runner.py:115} INFO - Job 269: Subtask Load_repositories_fact_table [2019-11-17 17:58:50,606] {cli.py:516} INFO - Running <TaskInstance: dend_dag.Load_repositories_fact_table 2018-11-03T04:00:00+00:00 [running]> on host likejundeMacBook-Pro.local
[2019-11-17 17:58:50,612] {load_facts.py:21} INFO - LoadFactOperator for repository_fact
[2019-11-17 17:58:50,617] {logging_mixin.py:95} INFO - [[34m2019-11-17 17:58:50,617[0m] {[34mbase_hook.py:[0m84} INFO[0m - Using connection to: [1mid: redshift. Host: redshift-cluster.chjcdyihped1.us-west-2.redshift.amazonaws.com, Port: 5439, Schema: dev, Login: awsuser, Password: XXXXXXXX, extra: {}[0m[0m
[2019-11-17 17:58:52,635] {logging_mixin.py:95} INFO - [[34m2019-11-17 17:58:52,635[0m] {[34mdbapi_hook.py:[0m171} INFO[0m - 
    INSERT INTO repository_fact
        (SELECT
            sp."repository id" AS repository_id,
            sp."repository stars count" AS stars,
            sp."repository forks count" AS forks,
            sp."repository watchers count" AS watchers,
            sp."repository contributors count" AS contributors,
            sp."repository size" AS size,
            sp."repository name with owner" AS repo,
            sv.id AS version_id,
            sv.project_id,
            sp."repository created timestamp" AS create_time,
            sd.id AS dependency_id
            FROM staging_projects sp
            JOIN staging_versions sv
            ON sp.id = sv.project_id
            JOIN staging_dependencies sd
            ON sp.id = sd."project id"
            WHERE sp."repository id" IS NOT NULL 
            AND TRUNC(sp."repository created timestamp") = "2018-11-03")
    [0m
[2019-11-17 17:58:53,575] {taskinstance.py:1051} ERROR - column "2018-11-03" does not exist in sp, sv, unnamed_join, sd, unnamed_join
Traceback (most recent call last):
  File "/Users/likejun/anaconda3/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 926, in _run_raw_task
    result = task_copy.execute(context=context)
  File "/Users/likejun/airflow/plugins/operators/load_facts.py", line 31, in execute
    pg_hook.run(stmt)
  File "/Users/likejun/anaconda3/lib/python3.7/site-packages/airflow/hooks/dbapi_hook.py", line 172, in run
    cur.execute(s)
psycopg2.ProgrammingError: column "2018-11-03" does not exist in sp, sv, unnamed_join, sd, unnamed_join

[2019-11-17 17:58:53,577] {taskinstance.py:1074} INFO - Marking task as UP_FOR_RETRY
[2019-11-17 17:58:53,589] {base_task_runner.py:115} INFO - Job 269: Subtask Load_repositories_fact_table Traceback (most recent call last):
[2019-11-17 17:58:53,589] {base_task_runner.py:115} INFO - Job 269: Subtask Load_repositories_fact_table   File "/Users/likejun/anaconda3/bin/airflow", line 32, in <module>
[2019-11-17 17:58:53,589] {base_task_runner.py:115} INFO - Job 269: Subtask Load_repositories_fact_table     args.func(args)
[2019-11-17 17:58:53,589] {base_task_runner.py:115} INFO - Job 269: Subtask Load_repositories_fact_table   File "/Users/likejun/anaconda3/lib/python3.7/site-packages/airflow/utils/cli.py", line 74, in wrapper
[2019-11-17 17:58:53,590] {base_task_runner.py:115} INFO - Job 269: Subtask Load_repositories_fact_table     return f(*args, **kwargs)
[2019-11-17 17:58:53,590] {base_task_runner.py:115} INFO - Job 269: Subtask Load_repositories_fact_table   File "/Users/likejun/anaconda3/lib/python3.7/site-packages/airflow/bin/cli.py", line 522, in run
[2019-11-17 17:58:53,590] {base_task_runner.py:115} INFO - Job 269: Subtask Load_repositories_fact_table     _run(args, dag, ti)
[2019-11-17 17:58:53,590] {base_task_runner.py:115} INFO - Job 269: Subtask Load_repositories_fact_table   File "/Users/likejun/anaconda3/lib/python3.7/site-packages/airflow/bin/cli.py", line 440, in _run
[2019-11-17 17:58:53,590] {base_task_runner.py:115} INFO - Job 269: Subtask Load_repositories_fact_table     pool=args.pool,
[2019-11-17 17:58:53,590] {base_task_runner.py:115} INFO - Job 269: Subtask Load_repositories_fact_table   File "/Users/likejun/anaconda3/lib/python3.7/site-packages/airflow/utils/db.py", line 74, in wrapper
[2019-11-17 17:58:53,590] {base_task_runner.py:115} INFO - Job 269: Subtask Load_repositories_fact_table     return func(*args, **kwargs)
[2019-11-17 17:58:53,590] {base_task_runner.py:115} INFO - Job 269: Subtask Load_repositories_fact_table   File "/Users/likejun/anaconda3/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 926, in _run_raw_task
[2019-11-17 17:58:53,590] {base_task_runner.py:115} INFO - Job 269: Subtask Load_repositories_fact_table     result = task_copy.execute(context=context)
[2019-11-17 17:58:53,590] {base_task_runner.py:115} INFO - Job 269: Subtask Load_repositories_fact_table   File "/Users/likejun/airflow/plugins/operators/load_facts.py", line 31, in execute
[2019-11-17 17:58:53,590] {base_task_runner.py:115} INFO - Job 269: Subtask Load_repositories_fact_table     pg_hook.run(stmt)
[2019-11-17 17:58:53,590] {base_task_runner.py:115} INFO - Job 269: Subtask Load_repositories_fact_table   File "/Users/likejun/anaconda3/lib/python3.7/site-packages/airflow/hooks/dbapi_hook.py", line 172, in run
[2019-11-17 17:58:53,590] {base_task_runner.py:115} INFO - Job 269: Subtask Load_repositories_fact_table     cur.execute(s)
[2019-11-17 17:58:53,590] {base_task_runner.py:115} INFO - Job 269: Subtask Load_repositories_fact_table psycopg2.ProgrammingError: column "2018-11-03" does not exist in sp, sv, unnamed_join, sd, unnamed_join
[2019-11-17 17:58:53,590] {base_task_runner.py:115} INFO - Job 269: Subtask Load_repositories_fact_table 
[2019-11-17 17:58:54,506] {logging_mixin.py:95} INFO - [[34m2019-11-17 17:58:54,505[0m] {[34mlocal_task_job.py:[0m105} INFO[0m - Task exited with return code 1[0m

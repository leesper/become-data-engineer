[2019-11-17 18:06:03,198] {taskinstance.py:620} INFO - Dependencies all met for <TaskInstance: dend_dag.Load_repositories_fact_table 2018-11-03T04:00:00+00:00 [queued]>
[2019-11-17 18:06:03,203] {taskinstance.py:620} INFO - Dependencies all met for <TaskInstance: dend_dag.Load_repositories_fact_table 2018-11-03T04:00:00+00:00 [queued]>
[2019-11-17 18:06:03,203] {taskinstance.py:838} INFO - 
--------------------------------------------------------------------------------
[2019-11-17 18:06:03,203] {taskinstance.py:839} INFO - Starting attempt 4 of 4
[2019-11-17 18:06:03,203] {taskinstance.py:840} INFO - 
--------------------------------------------------------------------------------
[2019-11-17 18:06:03,208] {taskinstance.py:859} INFO - Executing <Task(LoadFactOperator): Load_repositories_fact_table> on 2018-11-03T04:00:00+00:00
[2019-11-17 18:06:03,208] {base_task_runner.py:133} INFO - Running: ['airflow', 'run', 'dend_dag', 'Load_repositories_fact_table', '2018-11-03T04:00:00+00:00', '--job_id', '271', '--pool', 'default_pool', '--raw', '-sd', 'DAGS_FOLDER/dend_dag.py', '--cfg_path', '/var/folders/8q/nyxhvd6d55nfqjdbrybk6jpw0000gn/T/tmppjr8gd0g']
[2019-11-17 18:06:03,864] {base_task_runner.py:115} INFO - Job 271: Subtask Load_repositories_fact_table /Users/likejun/anaconda3/lib/python3.7/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
[2019-11-17 18:06:03,864] {base_task_runner.py:115} INFO - Job 271: Subtask Load_repositories_fact_table   """)
[2019-11-17 18:06:03,945] {base_task_runner.py:115} INFO - Job 271: Subtask Load_repositories_fact_table [2019-11-17 18:06:03,944] {__init__.py:51} INFO - Using executor SequentialExecutor
[2019-11-17 18:06:04,226] {base_task_runner.py:115} INFO - Job 271: Subtask Load_repositories_fact_table [2019-11-17 18:06:04,226] {dagbag.py:90} INFO - Filling up the DagBag from /Users/likejun/airflow/dags/dend_dag.py
[2019-11-17 18:06:04,239] {base_task_runner.py:115} INFO - Job 271: Subtask Load_repositories_fact_table [2019-11-17 18:06:04,239] {cli.py:516} INFO - Running <TaskInstance: dend_dag.Load_repositories_fact_table 2018-11-03T04:00:00+00:00 [running]> on host likejundeMacBook-Pro.local
[2019-11-17 18:06:04,252] {load_facts.py:21} INFO - LoadFactOperator for repository_fact
[2019-11-17 18:06:04,259] {logging_mixin.py:95} INFO - [[34m2019-11-17 18:06:04,259[0m] {[34mbase_hook.py:[0m84} INFO[0m - Using connection to: [1mid: redshift. Host: redshift-cluster.chjcdyihped1.us-west-2.redshift.amazonaws.com, Port: 5439, Schema: dev, Login: awsuser, Password: XXXXXXXX, extra: {}[0m[0m
[2019-11-17 18:06:06,926] {logging_mixin.py:95} INFO - [[34m2019-11-17 18:06:06,926[0m] {[34mdbapi_hook.py:[0m171} INFO[0m - 
    INSERT INTO repository_fact
        (SELECT
            sp."repository id" AS repository_id,
            sp."repository stars count" AS stars,
            sp."repository forks count" AS forks,
            sp."repository watchers count" AS watchers,
            sp."repository contributors count" AS contributors,
            sp."repository size" AS size,
            sp."repository name with owner" AS repo,
            sv.id AS version_id,
            sv.project_id,
            sp."repository created timestamp" AS create_time,
            sd.id AS dependency_id
            FROM staging_projects sp
            JOIN staging_versions sv
            ON sp.id = sv.project_id
            JOIN staging_dependencies sd
            ON sp.id = sd."project id"
            WHERE sp."repository id" IS NOT NULL 
            AND TRUNC(sp."repository created timestamp") = '2018-11-03')
    [0m
[2019-11-17 18:06:19,356] {load_facts.py:32} INFO - inserted into repository_fact
[2019-11-17 18:06:23,220] {logging_mixin.py:95} INFO - [[34m2019-11-17 18:06:23,220[0m] {[34mlocal_task_job.py:[0m105} INFO[0m - Task exited with return code 0[0m
